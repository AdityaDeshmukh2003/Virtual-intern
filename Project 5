# Import necessary libraries
import numpy as np
import matplotlib.pyplot as plt
from tensorflow import keras
from tensorflow.keras import layers

# Load the MNIST dataset
(x_train, _), (_, _) = keras.datasets.mnist.load_data()

# Normalize the pixel values to be between -1 and 1
x_train = x_train.astype("float32") / 127.5 - 1.0
x_train = np.expand_dims(x_train, axis=-1)

# Set up the generator model
generator = keras.Sequential(
    [
        layers.Dense(7 * 7 * 128, input_dim=100, activation="relu"),
        layers.Reshape((7, 7, 128)),
        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding="same", activation="relu"),
        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding="same", activation="relu"),
        layers.Conv2D(1, kernel_size=7, padding="same", activation="tanh"),
    ],
    name="generator",
)

# Set up the discriminator model
discriminator = keras.Sequential(
    [
        layers.Conv2D(64, kernel_size=3, strides=2, input_shape=(28, 28, 1), padding="same"),
        layers.LeakyReLU(alpha=0.2),
        layers.Conv2D(128, kernel_size=3, strides=2, padding="same"),
        layers.LeakyReLU(alpha=0.2),
        layers.GlobalMaxPooling2D(),
        layers.Dense(1, activation="sigmoid"),
    ],
    name="discriminator",
)

# Compile the discriminator
discriminator.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss="binary_crossentropy", metrics=["accuracy"])

# Set up the GAN model
discriminator.trainable = False
gan_input = keras.Input(shape=(100,))
x = generator(gan_input)
gan_output = discriminator(x)
gan = keras.Model(gan_input, gan_output, name="gan")

# Compile the GAN
gan.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss="binary_crossentropy")

# Train the GAN
batch_size = 64
epochs = 10000

for epoch in range(epochs):
    noise = np.random.normal(0, 1, (batch_size, 100))
    generated_images = generator.predict(noise)
    
    idx = np.random.randint(0, x_train.shape[0], batch_size)
    real_images = x_train[idx]
    
    labels_real = np.ones((batch_size, 1))
    labels_fake = np.zeros((batch_size, 1))
    
    d_loss_real = discriminator.train_on_batch(real_images, labels_real)
    d_loss_fake = discriminator.train_on_batch(generated_images, labels_fake)
    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)
    
    noise = np.random.normal(0, 1, (batch_size, 100))
    labels_gan = np.ones((batch_size, 1))
    
    g_loss = gan.train_on_batch(noise, labels_gan)
    
    if epoch % 100 == 0:
        print(f"Epoch {epoch}/{epochs} | Discriminator Loss: {d_loss[0]} | Generator Loss: {g_loss}")

        # Generate and save generated images
        generated_images = (generated_images + 1) / 2.0  # Rescale pixel values from -1 to 1 to 0 to 1
        fig, axs = plt.subplots(4, 4)
        count = 0
        for i in range(4):
            for j in range(4):
                axs[i, j].imshow(generated_images[count, :, :, 0], cmap="gray")
                axs[i, j].axis("off")
                count += 1
        plt.show()
